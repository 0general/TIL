● 인공지능이란?

사전적 의미 : 인간의 학습능력과 추론능력, 지각능력, 자연언어의 이해능력 등을 컴퓨터 프로그램으로 실현한 기술.
즉, 인간처럼 생각하고 행동하는 기기를 만드는 기술에 포함되는 모든 것!

● 일상 속 인공지능 
- 음성인식 (Siri)
- 추천 시스템 (eBay, Netflix)
- 자율주행 (Waymo)
- 실시간 객체 인식 (Face ID)
- 로봇 (HUBO)
- 번역 (papago)

실제로는 일상 속 인공지능의 기술을 월등히 뛰어넘은 상태이다.
예를 들어 듀플렉스는 이미 사람과 자연스러운 대화를 할 수 있다.
그러나 아직까지는 사회적인 통념이나 범주에 받아들여지지 않기때문에 
이미 기술이 많이 발전했음에도 불구하고 아주 적은 부분만이 실생활에 적용되어있다.

악용을 막거나 대응할 방법이나 법이 아직 정립이 되어 있지 않았기 때문.


● 인공지능의 역사
1940년부터 진행된 길고 긴 역사를 가진 인공지능


● 인공지능을 하려면, Python과 Open Source(남이 짜놓은 코드를 많이 보고 이해할 수 있어야 한다.)로 많이 소통하자.

● 인공지능의 구현
 인공지능은 레고처럼 조립이 가능하다.
 깊은 신경망 - 주어진 문제 목표 - 최적화

● 인공지능 구현의 협력자 = frameworks

frameworks 는 뼈대 역할을 하며 그 종류가 매우 다양하다.
-theano
-PYTORCH
-keras
- 
-


● 데이터 기반의 접근
데이터에 대한 이해도가 높고 그것에 대한 통찰력이 있다면 좀 더 고도화된 인공지능을 만드는 데 도움이 된다.

● 인공지능은 기술에 집중하기보다 인간 중심의 소통에 집중해야 한다.

만듦과 효율성에 치우치다보면 인간의 행위나 사고를 대체하기 위한 목적을 잃어버리게 된다. 
따라서 무엇보다도 인간의 삶에 대한 이해을 중심으로 두어야한다.

● 인공지능은 '도구'다.

- 도구를 만드는 방법도 중요하지만 도구 사용 방법도 배워야 한다.
  예를 들어, 수술용 칼로 사과를 깎아서는 안된다. 같은 도구라도 어떻게 사용하느냐에 따라 달라진다.
  딥페이크가 처음의 의도와는 달리, 가짜뉴스나 다른 범죄에 이용되는 일이 발생했던 것처럼 사용 방법과 사용 철학에 유념해야 한다.

- 지금은 인공지능이 선택이 아닌 필수가 되어버린 시대다.
  뛰어난 도구를 가지고 쓸 줄 아는 것은 시대를 선도하는 것 외에 시대를 따라가기 위해 필수가 된다.


● 교재 :
 기본도서 
 - 기계학습, 오일석
 참고도서 
 - Machine Learning : a Probabilistic Perspective by K. Murphy
 - Deep Learning by Goodfellow, Bengio, and Courville
 - Stanford CS231N 강의자료
 수업자료
 - ecampus.kookmin.ac.kr 수업 게시판 공유 예정

● 수업목표
 - 기초 기계학습과 인공지능의 이해
 - 인공신경망과 심층학습의 포괄적인 이해
 - 고급 소프트웨어 응용 실습 (Python with PyTorch) - 라이브코딩 도입 예정
 - 최신 인공지능 기술 흐름 파악

● 선수과목
 - 프로그래밍 (Python) [필수]
 - 선형대수(linear algebra) 및 확률통계(probaility and statistics), 정보이론(information theory)

● 바보같은 질문은 없으니 언제든 질문과 면담을 신청하자.

● 예습은 몰라도 복습은 반드시 해야 한다.
 학습은 무조건 반드시 하자!

_____________________________________________________________________________________________________________

● 사람/동물의 학습 vs 기계 학습
 - 수학, 과학, 역사 등 사고 영역 + 수영, 자전거 타기 등 행위 영역 포함
 - 파블로프의 개 실험
 
 + 기계도 학습이 가능한가?
 + 경험을 통해 점진적으로 성능이 향상되는 기계를 만들 수 있을까?


● 기계 학습의 정의 

- 인공지능(artificial intelligence)이란?
 인간의 학습, 추론, 지각, 자연언어 이해 등의 지능적 능력을 기기로 실현한 기술

- 학습이란?
 "경험의 결과로 나타나는, 비교적 지속적인 행동의 변화나 그 잠재력의 변화 또느느 지식을 습득하는 과정"

- 기계 학습 machine learning이란?
 > 인공지능 초창기 정의 :
        (경험은 data라고 생각하자.)
 > 현대적 정의 : 어떤 컴퓨터 프로그램이 T라는 작업을 수행한다. 
                이 프로그램의 성능을 P라는 척도로 평가했을 때 경험 E를 통해 성능이 개선된다면
                이 프로그램은 학습을 한다고 말할 수 있을 것이다.

                경험 E, 주어진 프로그램 T, 성능 P

● 기계학습과 전통적인 프로그래밍의 비교
 : 입력과 프로그램을 넣어 결과를 내는 것이 전통적인 프로그래밍, 입력과 기대하는 결과를 넣어 규칙을 찾아내는 과정이 기계학습


● 인공지능의 탄생 = 연산 장치의 탄생
 - 컴퓨터의 뛰어난 능력
    복잡한 연산을 사람보다 잘함
 - 컴퓨터에 대한 기대감 = 컴퓨터의 능력 과신
    사람의 지능 행위를 컴퓨터가 모방할 수 있을까 하는 호기심




■ 지식기반 방식에서 기계 학습으로의 대전환

● 초창기 지식기반 방식 주류
  - 지식기반 : 경험적인 지식 혹은 사실을 인위적으로 컴퓨터에 부여하여 학습

● 큰 깨달음
  - 지식기반의 한계
      학습의 대상이 심한 변화 양상을 가진 경우, 모든 지식 혹은 사실의 나열은 불가능

● 인공지능의 주도권 전환
  - 지식 기반 → 기계 학습 → 심층 학습 deep learning (표현 학습representation learning)
      보다 사람에 가까운 형태로 모방하며 구체화되고 있다.
  - 데이터 중심 접근방식으로 전환




■ 기계 학습 개념

● 간단한 기계 학습 예제

 - 가로축은 시간, 세로축은 이동체의 위치
 
   모든 데이터는 정향화된 형태로 표현되어야 한다. (예, 벡터)

 - 4개의 점이 데이터 관측


● 문제 task 예측 prediction

 - 임의 시간이 주어지면 이때 이동체의 위치는?

 - 예측은 회귀regression 문제와 분류 classification 문제로 나뉨

   회귀는 목표치가 실수, 분류는 부류 혹은 종류의 값


● 훈련집합 training set
 
 - 가로축은 특징, 세로축은 목표치
 - 관측한 4개의 점이 훈련집합을 구성함
 - 입력과 그에 대응하는 결과값 label으로 구성되어있다.

● 관찰된 데이터들을 어떻게 설명할 것인가?
 - 가설 hypothesis : 눈대중으로 데이터 양상이 직선 형태를 보임 → 모델을 직선으로 선택 가정
 - 가설인 직선 모델의 수식
   * 2개의 매개변수 parameter w와 b
    y = wx + by

● 기계 학습의 훈련 train
 - 주어진 문제인 예측을 가장 정확하게 할 수 있는 최적의 매개변수를 찾는 작업
 - 처음은 임의의 매개변수 값에서 시작하지만, 개선하여 정량적인 최적 성능 performance에 도달

 - 내가 세운 가설을 가장 잘 설명하는 parameter 값을 찾는다.
 - 내 가설과 실제 점의 차이 = 오차 = error = loss

● 훈련(경험을 통해 규칙을 찾아내는 과정)을 마치면, 추론 inference을 수행
 - 새로운 unknown 특징에 대응되는 목표치의 예측에 사용

● 기계 학습의 궁극적인 목표
 - 훈련집합에 없는 새로운 데이터에 대한 오류를 최소화 (새로운 데이터 = 테스트 집합 test set)
 - 테스트 집합에 대한 높은 성능을 일반화generalization 능혁이라 부름

   ※ 일반화 성능이 좋은 모델을 만드는 것이 기계학습의 궁극적인 목표이다.


● 기계학습의 필수요소
 - 학습할 수 있는 데이터가 있어야 함
 - 데이터 규칙 존재
 - 수학적으로 설명 불가능

학습의 목적 : 피드백을 받는 것 


◎ 특징 공간에 대한 이해능력
 ■ 1차원과 2차원 특징 공간
 ■ 다차원 특징 공간
 ■ 특징 공간 변환과 표현 학습


■ 1차원과 2차원 특징 공간

● 모든 데이터는 정량적으로 표현이 되어야 한다. 즉 특징 공간 상에 존재하게 된다.

● 1차원 특징 공간
  특징과 목표값을 축으로 표시할 경우 차원으로 보이지만, 목표값은 특징이 아니다. 특징만 표시할 경우 축은 하나.

● 2차원 특징 공간
  특징 벡터와 목표값을 축으로 표시할 경우 3차원으로 보인다. 특징 벡터만 축으로 표시할 시 축은 2개다.
 - 특징 벡터 표기


■ 다차원 특징 공간

● 다차원 특징 공간 예제
 - Haberman survival : (나이, 수술년도, 양성 림프샘 개수)의 특징으로 3차원 특징 공간을 가진다.
 - Iris : (꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 꽃잎 너비)의 특징을 가지고 있어서 4차원 특징 공간을 가진다.
 - MNIST : (화소 1, 화소 2, ..., 화소 784)의 특징으로 784차원 특징 공간을 가진다.
 

데이터의 특징 공간이라는 말을 잘 알아두도록 하자.


◇ 벡터로 표기하는 이유 : 벡터는 공간 상에 표시할 수 있고 벡터로 표시해야 컴퓨터가 알아듣는다.


● d-차원 데이터 
 - 특징 벡터 표기 : x = (x₁, x₂, ..., xd)^T

 - d-차원 데이터를 위한 학습 모델의 예

   + 직선 모델을 사용하는 경우 매개변수 수 = d+1
   + 2차 곡선 모델을 사용하면 매개변수 수가 지수적으로 증가, 매개변수 = d² + d + 1

 - 거리 : 차원에 무관하게 수식 적용 가능함
   
● 차원의 저주 curse of dimensionality (= number of features)
 - 차원이 높아짐에 따라 발생하는 현실적인 문제들
 - 1차, 2차, 3차원에서의 차원의 저주 예시
 - 예) d=784인 MNIST 샘플의 화소가 0과 1값ㅇ르 가진다면 2^(784)개의 칸
       이 거대한 공간에 고작 6만 개의 샘플을 흩뿌린 매우 희소한 분포

 - 차원이 높아질수록 유의미한 표현을 찾기 위해 지수적으로 많은 데이터가 필요함


 일반적으로 차원이 높아질수록 규칙이 찾기 더 어려워진다.

■ 특징 공간 변환과 표현 문제

○ 선형 분리 불가능 linearly non-seperable한 원래 특징 공간
 - 직선 모델을 적용하면 75%정확도 한계
○ 어떤 식으로 변환된 새로운 특징 공간 (특징 벡터를 변환)
 - 공간 변환을 통해 직선 모델로 100% 정확도

이건 중요한 문제다.
원 공간(직교 좌표계)에서는 표현하지 못했던 것을, 공간 변환을 통해 좌표계를 바꿔 직선으로 바꿀 수 있다면
이것을 표현 문제라고 한다.

● 표현 문제representations matter

● 표현 학습 representation learning
 - 좋은 특징 공간을 자동으로 찾는 작업
 - 표현 학습을 사람이 직관으로 수행한 셈이 된다. (사람이 개입하지 않음)

● 심층학습 deep learning
 - 표현 학습의 일종(향상시킨 것)으로  다수의 은닉층을 가진 신경망을 이용하여 최적의 계층적인 특징을 학습
 - 아래쪽 은닉층은 단순한 형태의 저급 특징(선, 구석점 등), 위쪽의 은닉층은 추상화된 특징(얼굴, 바퀴 등) 추출

 Image, Text, Speech 등 어느 곳이든 맞춰서 학습할 수 있기 때문에 주된 학습의 하나가 됐다.


■ 인공지능과 기계 학습의 간략한 역사

Ada Lovelace 여사의 통찰력 → 튜링 테스트 → .... → 

● 인공신경망의 역사
 - 1940-1960 : 인공두뇌학 cybernetics
 - 1980-1990 : 결합설 connectionism (or parallel distrubuted processing)
 - 2006~현재 : 심층학습 deep learning


■ 기술 추세
● 인공지능의 범주
 AI ⊃ Machine learning ⊃ Representation learning ⊃ Deep learning
 AI - Knowledge bases
 Machine learning - Logistic regression
 Representation learning - Shallow autoencoders
 Deep learning - (ex. MLPs)


● 기계학습 알고리즘과 응용의 다양화
● 표현 학습이 중요해짐
● 심층학습이 기계 학습의 주류(or 핵심)
● 심층학습은 현대 인공지능 실현에 핵심 기술

* Rule-based systems : 아주 초창기에 나온 학습. 전통적인 프로그래밍 
            ↓
* Classic machine learning : 모든 rule을 다 정의할 수는 없지만 사람들이 알고있는 rule들(=handcraft features)을 가공해서 규칙 찾기
            ↓
* Representation learning ( Deep learning 포함 ) : 입력이 들어왔을 때 사람이 개입하지 않고 경험을 통해 규칙을 잘 표현할 수 있게 만든다.

● Classic Machine Learning vs 표현학습 representation learning
  -차이점 : 사람의 개입 유무
  데이터 중심 data driven 표현 학습  
                        vs
                         사람 중심 human driven Classic Machine learning

* Deep learning : 고도화된 표현 학습. 각각의 특징을 세분화시켜서 점진적으로 추상화된 특징을 찾는다.

■ 사회 전망

● 인공지능의 단계
  약인공지능 (Weak AI) → 강인공지능 (Strong AI = 인공일반지능) → 초인공지능 (Super AI)
  - 초인공지능 : 인공지능의 발전이 가속화되어 모든 인류의 지성을 합친 것보다 더 뛰어난 인공지능
            인간을 넘어서는 특이점
  - 강인공지능 : 인간이 할 수 있는 어떠한 지적인 업무도 성공적으로 해낼 수 있는 (가상적인) 기계의 지능
            인간다운 인공지능으로의 변화 = 모든 상황에 두루 적용 가능
             + 인간의 오감을 인지하는 컴퓨터를 이용해 직관적인 간접체험 가능
             + 거대하고 어려운 사회문제의 해결
             + 획기적으로 달라지는 의료활동
             + 인지능력과 통신망을 통합해 모든 시스템을 스마트하게 변화
             + 인간의 의사결정시 센서 데이터 활용
             + 지식 암기 기반 교육과정 소멸 / 정부, 국가 기본제도와 운영 변화
             + 입법, 행정, 사법 기능 대체 / 정부, 국가 기본제도와 운영 변화
             인간의 삶을 이해하는 기계에 대한 초지능시대 진입
  - 약인공지능 : 인간이 지시한 명령의 틀 안에서만 일하기 때문에 예측과 관리가 용이
            최근, 약인공지능의 빠른 발전
            특정 분야ㅢ 일만 할 수 있도록 설계됨 → 종합적 판단에 한계를 보임

 
 현재는 약인공지능의 수준이다. 강인공지능의 단계로 올라가기 위해 노력하고 있다.


_____________________________________________________________________________________________________________

□ 데이터
■ 데이터에 대한 이해능력

● 과학 기술의 정립 과정 
  
   과학 기술의 발전 과정 : 데이터 수집 → 모델 정립(가설 hypothesis) → 예측 → 데이터 수집 → ... 
                                    자연의 규칙이나 법칙을 설명할 수 있는 가설
   예) - Tycho Brache는 천동설이라는 틀린 모델을 선택하여 수집한 데이터를 설명하지 못함
       - Johannes Kepler는 지동설 모델을 도입하여 제 1, 제 2, 제 3법칙을 완성함

● 기계학습
 - 기계학습은 복잡 문제/과업을 다룸
    지능적 범주의 행위들은 규칙의 다양한 변화 양상을 가짐
 - 단순한 수학 공식으로 표현 불가능함
 - 데이터를 설명할 수 있는 학습 모델을 찾아내는 과정
    Get Raw Data > Clean Data > "Build Model" > prediction

 눈에 보이지 않는 규칙에 의해 데이터들이 생성될 때, 데이터는 규칙의 일부라고 할 수 있다.
 이 데이터를 모아서 규칙을 찾기 위한 모델을 만드는 것이다.

 때로는 가설보다 데이터를 모으거나, 데이터를 전처리하는 것이 훨씬 중요할 수 있다.



■ 데이터 생성 과정

● 데이터 생성 과정을 완전히 아는 인위적 상황 (가상)
 - 실제로는 존재하지 않는다.
 - 수학적으로 모든 확률을 알고있는 경우는 새로운 데이터를 생성하는데 어려움을 겪지 않으며
   확률통계에서 다루지, 기계 학습에서는 다루지 않는다.
● 실제 기계 학습 문제 (현실)
 - 데이터 생성 과정을 알 수 없다.
 - 단지 주어진 훈련집합 X, Y로 가설 모델을 통해 근사 추정만 가능
 - 훈련집합에 발현된 규칙은 명확하게 알 수 없지만 훈련 집합을 완벽하게 설명하는 모델을 찾으면 규칙도 근사 추정을 할 수 있다.


■ 데이터의 중요성

● 데이터의 양과 질
 - 주어진 과업에 적합한 다양한 데이터를 충분한 양만큼 수집 -> 과업 성능향상
   예) 정면 얼굴만 가진 데이터로 인식 학습하면, 측면 얼굴은 아주 낮은 인식 성능을 가짐
    → 주어진 과업에 관련된 데이터 확보는 아주 중요함

 - 데이터의 양과 학습 모델의 성능 경향성 비교
    모델 용량(= 표현 능력)은 parameter가 많을수록 증가한다. 
    model capacitiy모델 용량
         : Classic machine learning(ex. SVM) < Shallow Neural Networks < Medium Neural Networks < Deep Neural Networks
    데이터가 많다면 모델 용량이 클수록 성능이 좋다.
    하지만 데이터가 적다면 모델 용량이 큰 모델들은 성능이 좋게 나오지 않을 것이다.

● 공개 데이터
 - 기계 학습의 대표적인 3가지 데이터 : Iris, MNIST, ImageNet

● Iris 데이터
 - 4가지의 특징을 가지고 있다. → 따라서 4차원 특징 공간이 형성된다.
 - 목표값으로 Species를 두고 3가지 class를 숫자 1,2,3으로 표현했다.

● MNIST 데이터
 - 미국표준국에서 수집한 필기 숫자 데이터베이스로, 훈련 집합 60,000자, 테스트집합 10,000자를 제공한다.
   매우 높은 성능을 달성한 모델과 더 나은 데이터들이 많이 나왔기 때문에 공부용도 외에 더 이상 사용되지는 않는다.

● ImageNet
 - 정보검색 분야에서 만든 WordNet의 단어 계층 분류를 따라서, 부류마다 수백에서 수천 개의 영상을 수집하였다.
   총 21,841개 부류에 대해 총 14,197,122개의 영상을 보유하고 있다. 
   이를 이용하여 사람의 인식 정확도를 뛰어넘는 결과를 낸 모델이 많이 나왔다.
   다른 방식으로도 사용될 수 있기 때문에 아직도 사용된다.

■ 데이터베이스 크기와 기계 학습 성능

● 데이터의 적은 양 → 차원의 저주와 관련
   - 예) MNIST : 28*28 단순히 흑백으로 구성된다면 서로 다른 총 샘플 수는 2^784가지이지만, MNIST는 고작 6만개 샘플

● 적은 양의 데이터베이스로 어떻게 높은 성능을 달성하는가?
 - 방대한 공간에서 실제 데이터가 발생하는 곳은 매우 작은 부분 공간임
   → 데이터 희소 data sparsity 특성 가정
    + 말도 안되는 데이터 발생 확률은 거의 0에 가깝다
 - 매니폴드(많이+끼다) 가정 manifold assumption (or manifold hypothesis)
    + 고차원의 데이터는
      관련된 낮은 차원의 매니폴드에 가깝게 집중되어 있음
    + 일정한 규칙에 따라 매끄럽게 변화한다. 

■ 데이터 가시화

● 4차원 이상의 초공간hyperplange은 한꺼번에 가시화 visualization 불가능
● 여러 가지 가시화 기법
 - 2개씩 조합하여 여러 개의 그래프 그림
 - 고차원 공간을 저차원으로 변환하는 기법들

□ 간단한 기계 학습의 예

● 선형 회귀 linear regression 문제
 - 직선 모델(가설)을 사용하므로 두 개의 매개변수 Θ = (w,b)^T


주어진 과업을 경험(데이터)를 통해서 성능 향상을 만드는 것이 학습에서 추구하는 바이다.
그럼 성능을 판단하는 기준은 무엇일까?
 = 목적 함수 or 비용 함수


● 목적 함수 objective function (또는 비용 함수 cost function)
 - 선형 회귀를 위한 목적 함수 J(Θ)를 평균제곱오차 MSE(mean squared)라 부른다.
  * 모델에 의해 발현된 예측값에서 실제값을 빼고 제곱한 것의 평균을 목적함수라 한다.
  * 예측값에서 실제값을 뺀 것을 오차 error 혹은 손실 loss라고 한다. 
 
 - 처음에는 최적 매개변수 값을 알 수 없으므로 임의의 난수로 Θ₁ = (w₁,b₁)^T
   → Θ₂ = (w₂,b₂)^T로 개선 → Θ₃ = (w₃,b₃)^T → 최적해 찾기
  * 이땐 평균제곱오차 J(Θ)₁ > J(Θ)₂ > J(Θ)₃ 점점 더 낮아진다.

● 선형 회귀 문제와 매개변수 최적화 관계의 예
 convex에 따라 다르지만 주로 미분(or Gradient)을 이용한다.

● 기계 학습이 할 일을 공식화하면, 작은 개선을 반복하여 최적의 해를 찾아가는 수치적 방법으로 푸는 것이다.

● 좀더 현실적인 상황
 - 지금까지는 데이터가 선형을 이루는 아주 단순한 상황을 고려함
 - 실제 세계는 선형이 아니면 잡음이 섞임 → 비선형 모델이 필요



● 기계 학습 요소
  - 예제 
    <카드 승인> 
      사람마다 feature와 value를 대응되도록 수집
      수집한 데이터를 통해 카드 발급 여부를 결정
    요소 : 
      - input ← DATA
      - output ← DATA
      - target distribution ← f = 궁극적으로 알고싶은, 눈에 보이지 않는 확률적인 분포 = 규칙
      - data
      - hypothesis
    특징 공간의 발현 : 눈에 보이지 않는 f에 의한 발현

● 기계학습 설정
  - 교사학습의 경우, 
    모르는 대상 UNKNOWN TARGET DISTRIBUTION을 유추하는 것이 핵심.
    
    UNKNOWN TARGET DISTRIBUTION이 필요하지 않는 경우도 있는데, 이 경우는 UNKNOWN INPUT DISTRIBUTION만이 필요하며,
    비교사 학습이라 한다.

    *데이터 : UNKNOWN TARGET DISTRIBUTION, UNKNOWN INPUT DISTRIBUTION, TRAIN EXAMPLES이 해당되고,
    *목적함수 : ERROR MEASURE
    *가설의 최적화 : LEARNING ALGORITHM, HYPOTHESIS SET, FINAL HYPOTHESIS 

  목적함수가 존재하지 않는 신경망이란 없다.
  목적함수를 잘못된 방법으로 쌓는다면 의미없는 결과가 나올 것이다.



□ 모델 선택
■ 과소적합과 과잉적합

● 과소적합 underfitting : 모델의 '용량이 작아' 오차가 클 수밖에 없는 현상
      모델의 용량 (= 모델의 자유도 ) ∝ parameter 수
  주어져 있는 규칙이 발현되어 있는 데이터를 못 따라가는 경우

● 대안 : 비선형 모델을 사용한다.
  1차(선형)에 비해 오차가 크게 감소한다.
  깊은 신경망을 쓸수록 자유도가 증가한다. 즉, 자유도를 높이면 underfitting을 해소할 수 있다.

● 과잉적합 overfitting : 모델의 '용량capacity이 크기' 때문에 학습 과정에서 잡음까지 수용하는 현상을 과잉적합 현상이라 한다.
   - 훈련집합에 과몰입해서 단순 암기했기 때문이다.
  자유도가 과도하게 높다면 잘못된 데이터나 잡음까지 학습해버려서 '새로운 데이터'를 예측하는데 큰 문제를 발생시킨다.

  따라서 적절한 용량의 모델을 선택하는 모델 선택 model selection 작업이 필요하다.


  ※ underfitting보다는 overfitting문제가 더 자주 발생한다.

● 1차 ~ 12차 다향식 모델의 비교 관찰 

 - 1~2차 훈련집합과 테스트집합 모두 낮은 성능 : 과소적합
 
 - 12차는 훈련집합에 높은 성능을 보이나 테스트집합에서는 낮은 성능 → 낮은 일반화 능력 : 과잉적합

 - 3~4차는 훈련집합에 대해 12차보다 낮겠지만 테스트집합에는 높은 성능 → 높은 일반화 능력 : 적합 모델 선택


● 모델의 일반화 능력과 용량 관계
  - Underfitting zone
    Optimal Capacity 에 도달하기 전까지 높았던 Training error와 Generalization error는 점차 낮아지는 모습을 보인다.
  - Overfitting zone
    하지만 Optimal Capacity 를 넘어가면 Training error는 계속 하락하지만 Generalization error 이 커지기 시작한다.

● 훈련집합에 대한 적합한 모델 Appropriate capacity 를 찾는 것이 중요하다.
  하지만 찾는 것은 어렵다.



■ 편향 bias 과 분산(변동) variance

● 훈련집합을 여러 번 수집하여 1차 ~ 12차에 반복 적용하는 실험

 - 2차는 매번 큰 오차 → 편향이 크다. 하지만 비슷한 모델을 얻는다. → 낮은 변동 
            훈련집합에 따라 데이터가 확확 바뀌거나 딸려가지 않는다.
 - 12차는 매번 작은 오차 → 편향이 작다. 하지만 크게 다른 모델을 얻는다 → 높은 변동
            변동이 크다는 것은 주어져 있는 훈련집합이 어떤 것인지에 따라 확확 바뀐다는 것이다.

 - 일시적으로 용량이 작은 모델은 편향이 크고 분산이 작다.
                    복잡한 모델은 편향이 작고 분산이 크다.

 - 편향bias과 분산은 상충 trade-off 관계다.

● 기계학습의 목표
  - 낮은 편향과 낮은 분산을 가진 예측 모델을 만드는 것이 목표이다. 
      ex. 높은 바이어스, 낮은 분산은 총을 쏠 때 과녘이 아닌 다른 타점만 모두 맞춘 경우라고 할 수 있다. ← 용량이 적으면 이렇게 된다
          높은 분산 높은 바이어스는 과녘 아닌 곳을 마구잡이로 맞춘 것.
          낮은 나이어스 높은 분산은 과녘을 맞추되 마구잡이로 맞춘 것이다. 과녘 위치가 달라지면 못 맞춘다. ← 용량이 큰 경우. 

  - 하지만 모델의 편향과 분산은 상충 관계
  - 따라서 편향을 최소로 유지하며 분산도 최대로 낮추는 전략 필요

● 편향과 분산의 관계 
 - 용량 증가 → 편향 감소, 분산 증가 경향
 - 일반화 오차 성능 (=편향+분산)은 U형의 곡선을 가짐



■ 검증집합과 교차검증을 이용한 모델 선택 알고리즘

● 검증집합을 이용한 모델 선택
 - 훈련집합과 테스트집합과 다른 별도의 검증집합 validation set을 가진 상황 (데이터 양 많음)
  
  > for (모델 집합에 있는 각각의 모델)
  >     모델을 훈련집합으로 학습시킨다.
  >     검증집합으로 학습된 모델의 성능을 측정한다. //검증 성능 측정
  > 가장 높은 성능을 보인 모델을 선택한다.
  > 테스트집합으로 선택된 모델의 성능을 측정한다.

 Validation set이 없다면 과잉적합 문제가 발생한다.

 Training set : 문제집 / Validation set : 모의고사 / Testing set : 수능

 Test data는 없다고 생각해라. 

● 교차검증 cross validation
 - 비용 문제로 별도의 검증집합이 없는 상황에 유용한 모델 선택 기법 (데이터 양 적음)
 - 훈련집합을 등분하여, 학습과 평가 과정을 여러 번 반복한 후 평균 사용

  > for (모델 집합에 있는 각각의 모델)
  >     for (i=1 to k)
  >         i번째 그룹을 제외한 k-1개 그룹으로 모델을 학습시킨다.
  >         학습된 모델의 성능을 i번째 그룹으로 측정한다.
  >     k 개 성능을 평균하여 해당 모델의 성능으로 취한다.
  > 가장 높은 성능을 보인 모델을 선택한다.
  > 테스트집합으로 선택된 모델의 성능을 측정한다.

● 부트스트랩 bootstrap
 - 임의의 복원 추출 샘플링 sampling with replacement 반복
   - 데이터 분포가 불균형일 때 적용

 - 샘플링 비율 p, 반복횟수 T

  > for (모델 집합에 있는 각각의 모델)
  >     for (i=1 to T)
  >         훈련집합 X에서 pn개 샘플을 뽑아 새로운 훈련집합 X'을 구성한다. 이때 대치를 허용한다.
  >         X'로 모델을 학습시킨다.
  >         X-X'를 이용하여 학습된 몯레의 성능을 측정한다.
  >     T 개 성능을 평균하여 해당 모델의 성능으로 취한다.
  > 가장 높은 성능을 보인 모델을 선택한다.
  > 테스트집합으로 선택된 모델의 성능을 측정한다.

● 위 세 개 알고리즘을 통해 주어진 모델 집합에서 선택
  - 현실에서는 학습 모델이 아주 다양하다.
    + 신경망 neural networks (MLP, deep MLP, CNN, RNN)
    + support vector machine(SVM)
    + decision trees
    + 등

● 현실에서는 경험으로 큰 틀(가설) 선택한 후
 - 모델 선택 알고리즘으로 세부 모델 선택함
   예) CNN을 사용하기로 정한 후, 모델 선택 알고리즘을 적용하여 해당 신경망의 세부 요소들을 정함

● 이런 경험적인 접근 방법은 항상 둥근 홈(우리가 선택한 모델)에 네모 막대기(데이터 생성 과정)을 끼워 넣는 것으로 비유할 수 있다.

● 현대 기계 학습의 전략
  - 용량이 충분히 큰 모델을 선택한 후, 
    선택한 모델이 정상을 벗어나지 않도록 여러 규제 regularization 기법을 적용함

    예) 12차 다항식을 선택하고, 적절히 규제를 적용


□ 규제

■ 데이터 확대 dataset augmentation

● 데이터를 더 많이 수집하면 일반화 능력이 향상됨
    - 변동량이 작아져 overfitting 문제가 해결될 수 있다.

● 데이터 수집은 많은 비용이 듦
  - 실측자료 ground truth 를 사람이 일일이 표식 labelling 을 해야 함

● 인위적으로 데이터 확대 data augmentation 
  - 훈련집합에 있는 샘플을 변형 transform 함
    예) 약간 회전 rotation 또는 왜곡 warping (원 데이터의 부류 소속 등의 고유 특성 변하지 않게 주의)



■ 가중치 감쇠 weight decay

● 가중치를 작게 조절하는 기법
 - 모델의 용량은 매개변수(가중치)와 비례한다. 

 - 가중치 감쇠는 개선된 목적함수를 이용하여 가중치가 작아지게끔 조절하는 규제 기법

 목적함수에 규제항을 추가 하여 가중치 크기를 작게 유지해줍니다.

● 가중치 감쇠를 가진 선형 회귀
   목적 함수 =  훈련집합의 오차 + 선호 preference (← w를 낮추는 규제용)

  - λ는 주어진 가중치의 감쇠 선호 정도를 제어
    + λ = 0 : 감쇠 없음
    + 큰 λ는 가중치가 더 작아지도록 한다.

  - Excessive λ : Underfitting
  - Medium λ    : Appropriate weight decay
  - λ → 0       : Overfitting

● 데이터 확대나 가중치 감쇠는 규제를 통해서 일반화 성능을 향상시킨다.


● 규제를 중요하게 다룬 책 [Goodfellow2016(7장)] [Haykin2009(7장)]
● 가중치 벌칙 parameter norm penalty
● 조기 멈춤 early stopping
● 데이터 확대 bagging (bootstrap aggregation)
● 드롭아웃 dropout
● 앙상블 ensemble methods 등



□ 기계 학습 유형
■ 지도 방식에 따른 유형

● 지도 학습 supervised learning
 - 특징 벡터 X와 목표치 Y (정답 있음)가 모두 주어진 상황 ← 어떤 규칙에 대한 증거 쌍을 주어주는 것
 - 회귀 regression 와 분류 classification 문제로 구분

● 비지도 학습 unsupervised learning
 - 특징 벡터 X는 주어지는데 목표치 Y가 주어지지 않는 상황 (정답 없음)
 - 군집화 clustering 과업 (고객 성향에 따른 맞춤 홍보 응용 등)
 - 밀도 추정 density estimation, 특징 공간 변환 과업 (예. PCA)

● 강화 학습 reinforcement learning
 - (상대적) 목표치가 주어지는데, 지도 학습과 다른 형태이다 (== 보상 reward) ← 과거에는 맞았지만 현재에는 틀릴 수도 있다. 상대적!
   예) 바둑
      - 수를 두는 행위(action)가 샘플인데, 행위로 인해 환경이 바뀐다. 게임이 끝나면 목표치 하나가 부여됨.
        + 이기면 1, 패하면 -1을 부여
      - 게임을 구성한 샘플들 각각에 목표치를 나누어 주어야 함
  알파고가 강화학습의 한 예이다.

● 준지도 학습 semi-supervised learning
 - 일부는 X와 Y를 모두 가지지만, 나머지는 X만 가진 상황
 - 최근, 대부분의 데이터가 X의 수집(unsupervised)은 쉽지만, Y는 수작업이 필요하여(일부만 supervised) 최근 중요성 부각


■ 다양한 기준에 따른 유형
● 오프라인 학습 offline learning 과 온라인 학습 online learning 
 - 보통은 오프라인 학습(이미 수집되어있는 데이터를 이용)을 다룸
 - 온라인 학습(데이터 실시간 추가)은 IoT 등에서 추가로 발생하는 데이터 샘플을 가지고 점증적 학습 수행

● 결정론적 학습 deterministic learning 과 확률적 학습 stochastic learning
 - 결정론적에서는 같은 데이터를 가지고 다시 학습하면 같은 예측 모델이 만들어짐
 - 확률적 학습은 학습 과정에서 확률 분포를 사용하므로
   같은 데이터로 다시 학습하면 다른 예측 모델이 만들어짐
   + RBM, DBN 이 확률적 학습

● 분별 모델 discriminative models 과 생성 모델 generative models
 - 분별 모델은 부류 예측에만 관심, 즉 P(y|x)의 추정에만 관심
 - 생성 모델은 P(x)또는 P(x|y)를 추정함
   + 따라서 새로운 샘플을 '생성'할 수 있음
   + GAN, RBM은 생성 모델
   + 순환신경망(RNN)을 생성 모델로 활용하는 응용 예제