
□ 기계 학습과 수학
■ 기계 학습에서 수학의 역할

● 수학은 목적함수를 정의하고, 목적함수의 최저점을 찾아주는 최적화 이론 제공
  성능적인 지표로서 파라미터(매개변수)를 찾는 과정에서 사용
● 최적화 optimization 이론에 학습률 learning rate, 멈춤조건과 같은 제어를 추가하여 알고리즘 구축
● 사람은 알고리즘을 설계하고 데이터를 수집

● 기계 학습은 수학, 알고리즘, 사람 이렇게 크게 3가지로 나뉜다.
  - 수학 : 목적함수 → 최적화
  - 알고리즘 : (수학) + 제어
  - 사람 : (알고리즘) ← 설계, 데이터(규칙) ← 수집

  사실 수학은 전반적인 모든 것에서 사용된다.


■ 선형대수

● 기계학습을 이해하기 위한 기본 선형대수 linear algebra
  어떤 벡터는 공간을 형성한다. 그리고 이 공간에 어떤 연산이 일어나느냐에 따라 공간이 변하거나 벡터의 값이 변할 수 있다. 

■ 벡터와 행렬

● 벡터 vector
  - 샘플을 특징 벡터 feature vector (or 입력벡터) 표현
    모든 데이터를 vector로 표현해야 한다.
  - 예) Iris 데이터에서 꽃받침의 길이, 꽃받침의 너비, 꽃잎의 길이, 꽃잎의 너비라는 4개의 각각 5.1,3.5,1.4,0.2인 샘플
  - 예) 사진도 각각의 pixel 값들이 또다시 각각 feature 값을 가지고 있기 때문에 행렬이나 tensor로 생각할 수 있다.
        이걸 하나의 열벡터로 표현할 수 있다.
  
  우리가 가지고 있는 데이터는 수치화될 수 있고 수치화되어야한다. 그 방법 중에 대표적인 것 하나가 vector다.

  - 요소의 종류(ex. 실수)와 크기(차원) 표현 

  - 데이터 집합의 여러 개 특징 벡터를 첨자(아래 첨자 or 위첨자. 책에 따라 다름)로 구분 


● 행렬 matrix
  - 여러 개의 벡터를 담음
  - 요소 : x(ij) i번째 행, j번째 열(x(:,j))
  - 훈련집합을 담은 행렬은 설계행렬 design matrix 이라 부름
    
  
벡터는 일반적으로 소문자로 쓰고, 행렬은 대문자로 쓰거나 볼드체로 쓰는 것이 대표적인 표현이다.


● 행렬 A의 전치행렬 transpose matrix  A^T
  행의 요소와 열의 요소가 서로 뒤바뀐다.

  - (A^T)ij = Aji
  - (AB)^T = (B^T)(A^T)

> 전치행렬을 쓰는 이유?
  우리가 표현해야할 데이터를 표현이나 연산에 사용하기 편하기 때문

● 행렬을 이용하면 방정식 (방정식계 system of equations)을 간결하게 표현 가능
  - 예) 다항식의 행렬 표현

  인공지능이나 신경망에서 우리가 처리해야할 데이터는 행렬이나 벡터이다. 

● 특수 행렬들
  - 정사각행렬(정방행렬 square matrix), 대각행렬 diagonal matrix, 단위행렬 identity matrix, 대칭행렬 symmetric metric

  결국 행렬은 공간이 변하게(transpose) 한다. 위 행렬들은 변환에서 특수한 의미를 갖는다.

● 행렬 연산
  - 행렬 곱셈 matrix (dot) product
    * 특성 
          : 교환 commutative 법칙  성립하지 않는다.
          : 분배 distributive 법칙과 결합 associative 법칙 성립
    
    행렬의 곱셈은 벡터의 내적의 합이다. 
  
  - 벡터의 내적 inner product
    * 내적은 유사도를 측정하는 값이다.
    * 두 벡터 사이에 적량화된 유사도를 구하는 것이 내적이다.

    벡터는 방향과 크기를 갖고 있는데, 내적은 벡터의 방향의 유사도를 보여준다. 
    내적 값이 0보다 크다면 서로 같은 방향, 유사도가 높다.
    내적 값이 0과 같으면 서로 직교
    내적 값이 0보다 작으면 서로 반대 방향, 낮은 유사도를 가지고 있음을 알 수 있다.

    신경망은 벡터의 내적과 비선형요소들을 이용


● 행렬 곱셈을 통해 벡터의 변환 transformation (function or mapping) 
  
  대부분은 선형적 변환이다.
  Ax = b : x라는 벡터가 있을 때 A를 곱해주면 b라는 새로운 공간으로 mapping된다.
           만일 x가 4차원, b가 2차원이라면 A는 x를 저차원 공간으로 투영시켜주는 역할을 하는 것이다.
           반대의 경우라면 확대
  그 대상이 행렬이든 벡터든 변환을 일으킨다는 점을 알아두자.

  - 대표적인 변환 : rotation, scale, reflect across   



■ 놈과 유사도

● 텐서 tensor
  - 3차원 이상의 구조를 가진 숫자 배열 array
    * 0차 = 수 scalar
    * 1차 = 벡터
    * 2차 = 행렬
    * 고차원..
  - 예) 3차원 구조의 RGB 컬러 영상

  텐서는 신경망 모델을 만들때 처리되는 기준점이 된다.


● 유사도 similarity와 거리 distance
  - 벡터(방향, 크기 둘 다 중요)를 기하학적으로 해석할 수 있다.

      > 유사도가 중요한 이유 
      > 유사도가 높을수록 비슷한 특징이나 비슷한 면을 많이 가지고 있다.
      > 거리도(맨하탄 거리, 유클리디안 거리 등)를 측정해서 유사도를 판단하기도 한다.
      > 결국 데이터들은 공간 안에 있고 그 공간 상에서 비슷한 특징들을 가지고 있으면 비슷한 판단을 할 수 있다.
  - 코사인 유사도 cosine similarity


■ 놈과 유사도

● 벡터와 행렬의 거리(크기)를 놈 norm 으로 측정
  - 벡터의 p차 놈
    주어져있는 공간에서 어떤 척도로 유사성을 판단할지 차이가 있다.
      * p차 놈 : 벡터의 모든 요소들의 절대값 혹은 p제곱(차수 p)들의 합을 1/p제곱(p제곱근)한 것
      * 최대 놈 : 각각 요소들의 절대값의 최대값
    
    + 1차(p=1)놈 absolute-value norm
      물리적인 의미 : 0점으로부터 크기가 1인 요소값들 (절대값 모양)
    + 2차(p=2)놈 Euclidean norm
      물리적인 의미 : 원의 형태

    + 최대 (p=infinite) 놈 max norm
      물리적인 의미 : 정사각형 형태

  
  - 행렬의 프로베니우스 놈 Frobenius norm : 행렬의 크기를 측정하는
    각각 요소 값들의 제곱의 합에 루트를 씌운다.
    얼마만큼의 크기를 가지고 있는지 판단하는 기준이 된다.

● 1차 놈 (L¹ : Manhattan distance)과 2차 놈 (L² : Euclidean distance) 비교
  - 거리(크기)의 경우

  - 하강 기울기의 규제 경우,
    손실값을 최소로 만들어주는 값을 찾아줄텐데 이를 공간적인 측면에서 보면 
    optimal한 포인트는 parameter가 모두 발현이 될 확률이 높다(train에 맞춤). overfitting을 막아주기 위해 
    norm을 벗어나지 못하도록 boundary를 쳐주는 것이다.



■ 퍼셉트론의 해석

● 퍼셉트론 perceptron
  사람의 뉴런으로부터 고안된 퍼셉트론

  - 퍼셉트론의 구조와 동작
    (a) 퍼셉트론 구조 : 입력값의 각각의 요소를 가중치( w, 기준값이라고 생각 )와 곱하여 하나로 합해 모은다. (← 내적과 동일)
    (b) 계단형 활성함수(비선형) : (a)에서 하나로 모아진 값을 thresholding 한다.
    (c) 퍼셉트론의 공간 분할 : thresholding 에 의해 + or -라고 이진 분류를 한다. 


  - 1958년 고안한 분류기 classifier 모델
  
  - 퍼셉트론의 동작을 수식으로 표현하면 
    o = τ(w·x), 이 때 τ(a) = 1 (a ≥ T) or -1 (a < T)

    활성 함수 activation function τ로는 계단함수(Heaviside) step function 사용

  퍼셉트론의 역할 : 기준점을 두고 thresholding을 해서 이진 분류를 한다.

  중요한 것은 내적!

● 퍼셉트론 물리적 의미
  - 두 개의 부분공간을 나누는 결정직선 decision line
    + 결정직선은 기준값 w에 수직이고 원점으로부터 T/(||w||₂)만큼 떨어져 있다.

  3차원 특징공간은 결정평면 decision plane, 4차원 이상은 결정 초평면 decision hyperplane
    + 예) 3차원 특징공간을 위한 퍼셉트론은 2부류로 공간 분할을 한다.

  
  결국 퍼셉트론은 내가 주어져있는 데이터 값을 기준에 비춰서 필터링하겠다는 의미를 갖는다. (2진 분류가 된다.)
  퍼셉트론 하나가 filter라고 생각하자.

● 여러 개의 퍼셉트론 출력 표현
  각각의 퍼셉트론이 가지고 있는 d차원의 가중치( 입력이 d차원이니까 같아야 )가 있어야 한다.
  퍼셉트론의 개수가 c개일 때, 총 c(퍼셉트론)개로 이루어진 벡터 o를 출력하게 된다. 

  첫 번째 퍼셉트론의 출력 o₁, 두 번째 퍼셉트론의 출력을 o이라고 할 때
  * 출력은 벡터 ｏ = (o₁, o₂, o₃, ..., oc)^T라고 표기한다.

  * j번째 퍼셉트론의 가중치 벡터를 ｗj = (ｗj1, ｗj2, ..., ｗjd)^T 로 표기한다.


  - 동작은 수식으로 표현하면, 

    ｏ = τ(Wx), W = (w₁^T, w₂^T, ..., wc^T)^T이다.

  퍼셉트론은 우리가 알고있는 벡터와 행렬의 계산으로 표시하기 굉장히 쉽다. 

  각각의 출력값들은 각 퍼셉트론의 기준값에 비추어서 입력값을 바라보겠다는 의미이다.

● 선형 분류기 이해
  10개의 클래스로 나오는 선형 분류기는 10개의 퍼셉트론을 가진다.
  10개의 퍼셉트론의 출력값은 각 기준값에 비추어서 입력값을 보았을때의 score가 된다. 
  score가 가장 큰 값은 가장 유사한 값을 가지고 있음을 드러내므로 해당 클래스에 해당하는 입력이라고 판단한다.


  
  - 가중치 벡터를 각 부류의 기준 벡터로 간주하면, c개 부류의 유사도 계산하는 것과 유사

● 학습의 정의
  - 추론 inferring : 학습을 마친 알고리즘을 현장의 새로운 데이터에 적용하는 작업
    분류라는 과업 : o = τ(Wx)
                   o ← ?,  W ← 앎, x ← 앎

  - 훈련 training : 훈련집합의 샘플에 대해 식을 가장 잘(올바르게) 만족하는 W를 찾아내는 작업
    학습이라는 과업 : o = τ(Wx)
                     o ← 앎, W ← ?, x ← 앎

  내적 연산, 곱셈이라는 것을 잘 알아두자.


● 현대 기계 학습에서 심층학습은 퍼셉트론을 여러 층으로 확장하여 만듦
  수학적으로(선형대수적인 측면에서) 의미를 확장한 것이 핵심

■ 선형결합과 벡터공간

●  벡터
  - 공간상의 한 점으로 화살표 끝이 벡터의 좌표에 해당

● 선형결합이 만드는 벡터공간
  - 기저 basis 벡터 a와 b의 선형결합 linear combination

  c = α₁a+ α₂b

  - 선형결합으로 만들어지는 공간을 벡터공간 vector space이라 부름


■ 역행렬
● 역행렬 matrix inversion의 원리
  역수의 원리와 비슷하게 변환되기 이전의 공간으로 다시 돌려주는 것은 역행렬이라고 한다.

  변환된 공간의 점에 변환의 역행렬을 곱해주면 이전 공간의 본래 점으로 돌아간다.

● 역행렬을 활용한 방정식 표현과 해
  - 방정식 Ax = b의 확장
    * A ∈ R^(m×n) : 알고 있는 행렬
    * b ∈ R^n : 알고 있는 벡터
    * x ∈ R^m : 알고 싶은 모르는 벡터
  
  - 선형 방정식의 경우
    * 불능 : 해 없음
    * 부정 : 다수의 해 존재
    * 유일해 존재 : 역행렬을 이요하여 해를 구함

● 정리
  ※ 필요충분 조건
   - A는 역행렬을 가진다. 즉 특이행렬이 아니다.
   - A는 최대 계수를 가진다.
   - A의 모든 행이 선형독립이다.
   - A의 모든 열이 선형독립이다.
   - A의 행렬식은 0이 아니다.
   - A^TA는 양의 정부호 positive definite 대칭 행렬이다. ← 이런 경우에만 역행렬이 존재한다.
   - A의 고윳값은 모두 0이 아니다.

● 행렬 A의 행렬식 determinant det(A)

  - 역행렬의 존재 유무
    * det(A) = 0 역행렬 없음
    * det(A) ≠ 0 역행렬 존재
  - 기하학적 의미 : 행렬식은 주어진 행렬의 곱에 의한 공간의 확장 또는 축소 해석
    * 만약, det(A) = 0, 하나의 차원을 따라 축소되어 부피를 잃게 됨
    * 만약, det(A) = 1, 부피 유지한 변환/방향 보존 됨
    * 만약, det(A) = -1, 부피 유지한 변환/방향 보존 안 됨
    * 만약, det(A) = 5, 5배 부피 확장되며 방향 보존
  
  원 공간에 대한 부피의 변화를 측정한다.

● 정부호 definiteness 행렬
  행렬의 공간이 어떻게 생겼는지 판단할 때 사용

  양의 정부호 행렬 : 0이 아닌 모든 벡터 x에 대해, x^(T)Ax>0

  - 성질 
    + 고유값 모두 양수
    + 역행렬도 정부호 행렬
    + det(A) ≠ 0 역행렬 존재

● 정부호 행렬의 종류

  양의 준정부호 positive semi-definite 행렬 : 0이 아닌 모든 벡터 x에 대해, x(^T)Ax ≥ 0
  음의 정부호 negative definite 행렬        : 0이 아닌 모든 벡터 x에 대해, x(^T)Ax < 0
  음의 준정부호 negative semi-definite 행렬 : 0이 아닌 모든 벡터 x에 대해, x(^T)Ax ≤ 0



■ 행렬 분해
● 분해 decomposition란?
  정수를 소인수 분해를 하면 특성이 보이듯이 행렬도 분해하면 여러모로 유용하다.

● 고윳값 eigenvalue 과 고유 벡터 eigenvector
  - Av = λv : 고유 벡터 v와 고윳값 λ
    * 2차원 공간에서의 고윳값과 고유 벡터의 기하학적 해석

    고유 벡터 축은 조금의 변환도 없이 오로지 scale 크기만 변한다.

● 고윳값과 고유 벡터의 효과
  행렬 A의 곱에 의해 단위벡터 u ∈ R²의 모든 점이 Au의 모든 점으로 변환될 때
   → A는 고유벡터 방향으로는 고유값만큼 크기 변환만 시킨다.
  
  즉 A에 의해 A공간이 변환할 때 고유벡터는 방향 변환없이(축이 바뀌지 않고) scale만 바뀌게 된다.

  A에 의해 공간이 바뀌게 되고 그 공간이 가지고 있는 어떤 기준점이 되는 것이다.


  고유값과 고유 벡터는 행렬의 역행렬도 구할 수 있고 PCA를 할 때도 사용가능하다.

● 고유 분해 eigen-decomposition
  - A = QΛQ(^-1)
    * Q는 A의 고유 벡터를 열에 배치한 행렬이고 Λ는 고윳값을 대각선에 배치한 대각행렬
    * A = QΛQ(^T)

  역행렬 사용할 때 활용됨

  - 고유 분해는 고유값과 해당 고유 벡터가 존재하는 정사각행렬에만 적용 가능
  - 하지만, 기계 학습에서는 정사각행렬이 아닌 경우의 분해도 필요하므로 고유 분해는 한계

■ 행렬 분해

● n*m 행렬 A 의 특잇갑사 분해 SVD (singular value decomposition)
  - A = U∑V^T
    * 왼쪽 특이행렬 U : AA^T의 고유 벡터를 열에 배치한 n*n 행렬
    * 오른쪽 특이행렬 V : A(^T)A의 고유 벡터를 열에 배치한 m*m 행렬
    * ∑ : AA^T의 고윳값의 제곱근을 대각선에 배치한 n*m 대각행렬

  분해를 해놓으면 역행렬을 쉽게 구할 수 있다.

● 특잇값 분해의 기하학적 해석
  
  특이 행렬은 고유벡터들의 조합을 가진 Q와 비슷 , diagonal 성분에 배치한 것은 고윳값과 비슷
  
  - A = U∑V^T
        * V^T : 회전 변환
                ↓
        * D :  크기 변환
                ↓
        * U : 회전 변환

  - 특이값 분해는 정사각행렬이 아닌 행렬의 역행렬 계산에 사용됨

    정사각행렬이 아닌 A를 SVD로 분해하면 A = U ∑ (V^T)이고 
    A의 역행렬은 V(∑의 역치)(U^T) 이다.

    ∑ = [σ₁       
           .
            .
             .
              σs
              0 ]

    ∑의 역치 = [1/σ₁        
                    .
                     .
                      .
                      1/σs 0 ]

    
선형대수 측면에서 접근한 공간과 데이터
________________________________________________________________________________________________________________

□ 확률과 통계 
■ 확률과 통계

● 기계 학습이 처리할 데이터는 불확실한 세상에서 발생하므로, 불확실성 uncertainty 을 다루는 확률과 통계를 잘 활용해야 함.

functino이 아닌 distribution이라고 하는 이유 : 우리가 알수없는 불확실성, 잡음이 들어간다. 
알고싶어하는 것을 정확하게 알지 못하기 때문에 우리는 target을 알기위해 가설(모델)을 세워서 가까운 것을 찾는다.


□ 확률 기초

● 확률변수 random variable

  불확실성에 의해서 인위적으로 변화할 수 있는 변수

  - 예) 윷
        도, 개, 결, 윷, 모 다섯가지 경우 중 한 값을 갖는 확률변수 x → x의 정의역 domain : {도, 개, 걸, 윷, 모}
  
  random처럼 보이지만 우리가 정의할 수 있는(통계적이든 확률적이든 설명할 수 있는) 규칙이 존재하는 것이 확률변수의 특징 중의 하나이다.

● 확률분포 probability distribution 
  - 확률질량함수 probability mass function : 이산 discrete 확률 변수
      각 확률은 불확실성이다. 대체적으로 이런 확률분포를 따른다는 것이지, 반드시 이게 나온다는 의미가 아니기때문.

  - 확률밀도함수 probability density function : 연속 continuous 확률 변수
     
● 확률벡터 random vector
  - 확률변수를 요소로 가짐
      예) Iris에서 x는 4차원 확률 벡터 x = (x₁,x₂,x₃,x₄)^T = (꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 꽃잎 너비)^T
          꽃받침 길이나 너비나 이런 것들 하나하나가 random variable 이다.

  우리가 다루는 대부분의 데이터(x)는 P(x)라는 확률분포에 의해 생성이 된다.
  이 생성된 것들이 Y로 발현되거나 하는 인과성을 찾는 것이 '교사 학습법'
  P(x)의 대상 자체에 대해서 x를 보고 처리하겠다는 것이 '비교사 학습법'


● 간단한 확률실험 장치
  - 주머니에서 번호를 뽑은 다음, 번호에 따라 해당 병에서 공을 뽑고 색을 관찰함
  - 번호를 y, 공의 색을 x라는 확률변수로 표현하면 정의역은 y ∈ 숫자, x ∈ 색



● 곱 (AND)규칙 product rule과 합 (OR) 규칙 sum rule
  곱의 규칙을 사용할 때는 종속 관계를 확인해야 한다.
  - 조건부 확률 conditional probability 에 의한 결합확률 joint probability(동시에 일어남) 계산
  - 합 규칙과 곱 규칙에 희한 주변확률 marginal probability 계산

● 조건부 확률
  P(Y = y|X = x) = P(Y=y,X=x)/P(X=x)

  

● 확률의 연쇄 법칙 chain rule
  P(x(1), ..., x(n)) = P(x(1))∏[i=2,n]P(x(i)|x(1), ...,x(i-1))

● 독립 independence

  서로 연관성이 없다.
  엄청나게 강력한 가정이라 이런 경우는 거의 없다.
  ∀x ∈ X, y ∈ Y, p(X=x, Y=y)=p(X=x)p(Y=x)


● 조건부 독립 conditional independence

  z가 주어졌을 때, x와 y는 서로 독립
  ∀x ∈ X, y ∈ Y, Z ∈ z, p(X=x, Y=y|Z=z)=p(X=x|Z=z)p(Y=x|Z=z)

  

● 기대값 expectation

  Ex~P[f(x)] = ∑[x]P(x)f(x)


■ 베이즈 정리와 기계 학습

● 베이즈 정리 Bayes's rule
  P(y,x) = P(x|y)P(y) = P(x,y) = P(y|x)P(x)  →  P(y|x) = P(x|y)P(y)/P(x)

  우리가 다루려고 하는 대부분의 문제에서 특히 분류기나 tartget distribution 에서는 베이즈 정리를 많이 사용한다.

  ex) "하얀 공이 나왔다는 사실만 알고 어느 병에서 나왔는지 모르는데, 어느 병인지 추정하라."

  우리가 원하는 상황이 제공된 데이터로는 구할 수 없는 경우는 베이즈 정리를 사용해서 데이터를 다시 정량화한다.


● 베이즈 정리의 해석
  - 사후 posteriori 확률 = 우도 likelihood 확률 * 사전 prior 확률

    사후확률   우도 사전확률
       ↓        ↓     ↙
    P(y|x) = P(x|y)P(y)/P(x)  

  이미 일어나고 나서 원인을 찾는 사후확률
  우도는 구할 수 있다. 데이터 샘플을 이용해서 직접 해보면 됨.
  사전 확률도 이미 알고 있는 것이다.


  기계학습은 대개 사후확률에 관심이 있고 이 사후확률을 풀고 싶어한다.


● 확률과 우도

  확률은 어떤 분포에서 우리가 가질 수 있는 모든 숫자를 정량화시켜놓고 이 데이터에서 유추하는 것이다.
  즉 확률은 정확한 것이다.

  우도는 내가 관심있는 것만 보고 확률에서 추론해내는 것이다.
  즉 부정확하지만 (직접적으로 구하지 못할 수도 있는 분포 대신) 쉽게 구할 수 있는 것이다.

● 기계 학습에 적용
  
  예) Iris 데이터 분류 문제
    - 특징 벡터 x, 부류 y∈{setosa, versicolor, virginica}
    - 분류 문제를 argmax로 표현하면 

          ^
          y = argmax P(y|x)
                 y


        특징추출 → x = (7.0,3.2,4.7,1.4)^T
        사후 확률 → 추정  P(setosa|x) = 0.18, P(versicolor|x) = 0.72, P(virginica|x) = 0.10 
        argmax → versicolor

    - 사후확률 P(y|x)를 직접 추정하는 일은 아주 단순한 경우를 빼고 불가능
    - 따라서 베이즈 정리를 이용하여 추정함
      + 사전확률 : P(y=ci) = ni/negative
      + 우도확률은 밀도 추정 density estimation 기법으로 추정 (내가 구할 수 있거나, 기존에 알고있음)

■ 최대 우도

● 매개변수(모수) parameter Θ 를 모르는 상황에서 매개변수를 추정하는 문제

  데이터 X가 주어졌을 때, X를 발생시켰을 가능성을 최대로 하는 매개변수 Θ 의 값을 찾아라.


● 최대 우도 maximum likelihood
  -어떤 확률변수의 관찰된 값들을 토대로 그 확률변수의 매개변수를 구하는 방법

  확률변수의 매개변수 : 확률분포를 설명하는 요소
   
  최대 우도 문제 = 내가 관찰된 것을 통해서 눈에 보이지 않는 매개변수를 가장 그럴듯하게 설명하자.

  - 최대 우도 추정 :
          ^
          Θ = argmax P(X|Θ)
                Θ
    
  눈에 보이지 않아 모르는 확률분포 Θ가 있을 때 이 확률분포로부터 발현되는 X값만 보고 
  Θ 를 설명해줄 수 있는 그럴듯한 likelihood를 만드는 것.


  최대 우도 문제는 log를 많이 쓴다.
  왜 log를 많이 쓰는가?
   일반적으로 곱셈으로 표현되는 P(X|Θ)이지만 그 곱을 다 표현하기엔 어렵다. 
   어차피 우리가 구해야 할것은 최대값이며 log를 씌운다고 해서 구하려는 max값이 달라지지 않는다. 
   다만 곱이 합으로 바뀔 뿐이다.

   즉, 계산을 간단하게 하기 위해 log를 많이 쓴다. 

  - 최대 로그우도 추정 :
          ^
          Θ = argmax logP(X|Θ) = argmax ∑[i=1,n] logP(xi|Θ)
                Θ                   Θ

■ 평균과 분산
● 데이터의 요약 정보로서 평균 mean 과 분산 variance
  
  - 평균 μ = (1/n)∑[i=1,n]xi 
  - 분산 σ² = (1/n)∑[i=1,n](xi-μ)² → Var(f(x)) = E[(f(x) - E[f(x)])²]: 평균 값을 기점으로 얼마나 퍼져있는가 (나와 나의 상관관계)


● 평균 벡터(치우침 정도)와 공분산 행렬 covariance matrix (확률변수의 상관정도)

  평균 벡터 : 평균을 스칼라 값이 아닌 벡터(다차원이기 때문에)로 볼 때 각 차원의 평균값을 표시
  공분산 행렬 : (만일 각각의 차원간의 상관관계가 있다면) 차원들간의 상관관계를 나타내는 것이 공분산 행렬이다. 모든 차원의 경우를 다 다룬다.


■ 유용한 확률분포

● 가우시안 분포 Gaussian distribution
  평균과 분산 두가지 요소만으로 설명할 수 있다.

  - 평균 μ와 분산 σ²으로 정의

  - 다차원 가우시안 분포 : 평균벡터 μ와 공분산행렬 Σ로 정의
    


● 베르누이 분포 Bernoulli distribution
  - 성공(x=1) 확률 p이고 실패(x=0) 확률이 1-p인 분포

    Ber(x;p) = p^x * (1-p)^(1-x) 
  
  한 번!

● 이항 분포 Binomial distribution

  - 성공 확률이 p인 베르누이 실험을 m번 수행할 때 성공할 횟수의 확률분포

    B(x;m,p) = mCx * p^x * (1-p)^(m-x)

  베르누이 시행을 여러 번 확대!


  - 확률질량 함수



● 확률 분포와 연관된 유용한 함수들

 - 로지스틱 시그모이드 함수 logistic sigmoid function
   + 일반적으로 베르누이 분포의 매개변수를 조정을 통해 얻어짐
   
   x가 들어오면 y로 발현되는데 y값의 분포가 0~1이다.
   비선형 함수로, 활성 함수로 많이 사용된다.

 - 소프트플러스 함수 softplus function
   + 정규 분포의 매개변수의 조정을 통해 얻어짐

   마찬가지로 비선형 함수로, 활성함수로 사용된다.


● 지수 분포 exponential distribution

● 라플라수 분포 Laplace distribution

● 디랙 분포 Dirac distribution

● 혼합 분포들 Mixture Distributions

  확률 분포를 여러 개 써서 설명하겠다. 

● 변수 변환 change of variables
  - 기존 확률변수를 새로운 확률 변수로 바꾸는 것
    기존에 있던 것과 새로운 것과의 상관관계가 있어야만 한다.
  - 변환 y=g(x)와 가역성을 가진 g에 의해 정의되는 x,y 두 확률변수를 가정


확률적으로 표현될 수 있는 것들을 확률적으로 접근해서 가설을 세우고 문제를 풀 수 있다.

베이지안 정리(사후 확률을 직접 구할 수 없어서 사전확률과 우도를 이용하여 접근)를 잘 기억해두자.
________________________________________________________________________________________________________________

■ 정보이론

● 정보이론과 확률통계는 만은 교차점을 가짐

● 확률통계는 기계학습의 기초적인 근간 제공
 - 해당 확률 분포 추정
 - 확률 분포 간의 유사성 정량화

→ 정보이론 관점에서도 기계학습을 접근 가능
 - 불확실성을 정량화하여 정보이론 방법을 기계학습에 활용한 예
   예) 엔트로피, 교차 엔트로피, KL 발산 kullback-Leibler divergence(상대 엔트로피 relavie entropy)

   힘의 정도인 엔트로피

● 정보이론 : 사건 event 이 지닌 정보를 정량화 할 수 있나?
 - "아침에 해가 뜬다"와 "오늘 아침에 일식이 있었다"라는 두 사건 중 어느 것이 더 많은 정보를 가지나?
    -> 일식이라는 특별한 사건이 더 많은 정보를 가짐
 - 정보이론의 기본 원리 → 확률이 작을수록 많은 정보
   - 자주 발생하는 사건보다 잘 일어나지 않는 사건 unlikely event 의 정보량 informative 이 많음

  통신 채널의 측면에서 봐야한다. 전달해야 할 정보량이 많아진다는 건은 더 많은 채널에서 전달해야 한다.


● 자기 정보 self information
 - 사건(메시지) eｉ의 정보량
   (단위 : 로드의 밑이 2인 경우, 비트 bit 또는 로그의 밑이 자연상수인 경우, 나츠 nat)
   h(eｉ) = -log₂P(eｉ) 또는 h(eｉ) = -lnP(eｉ)


● 엔트로피 entropy
 - 확률변수 x의 불확실성을 나타내는 엔트로피
 - 모든 사건 정보량의 기대 값(-∑P(e)logP(e))으로 표현

 즉 정보량이다.

 모든 자기정보를 구하고 거기에 자기자신의 확률값을 곱해서 기댓값을 구한다.
 불확실성을 정량화해준 것을 의미한다.

● 교차 엔트로피 cross entropy : 두 확률분포 P와 Q 사이의 교차 엔트로피
  두 개의 확률분포가 얼마나 정보를 공유하고 있는지를 판단하는 지표로 활용한다.

  H(P,Q) = - ∑ P(x)log₂Q(x) = - ∑ P(eｉ)log₂Q(eｉ)
  
  P : 데이터가 만드는 분포 (= 예측값), Q : 대상
  - 심층학습 deep learning 의 손실함수로 많이 사용됨
        deep learning에서의 출력값은 어떤 확률값이다. 또한 손실함수는 정답과 예측값을 비교한다.
        손실함수 입장에서는 두 개를 정량화해서 얼만큼 떨어져있는지를 봐야한다. 즉 두 개의 확률분포로 볼 수 있는 것을 비교해야 하기 때문에 
        교차 엔트로피는 손실함수로 적합하다.
  - 식을 전개하면,
          H(P,Q) = - ∑ P(x)log₂Q(x)
                 = - ∑ P(x)log₂P(x) + ∑ P(x)log₂P(x) - ∑ Q(x)log₂Q(x)
                 = H(P) + ∑ P(x)log₂(P(x)/Q(x))
                              ↑ KL 발산 divergence
     + 여기서 P를 데이터의 분포라고 하면, P값은 학습 과정에서 변화하지 않기 때문에 최소화 불가능하다.
      → 교차 엔트로피를 손실함수로 사용하는 경우, KL 발산의 최소화함과 동일                   
        

● KL 다이버전스
  - 우리가 맞추고 싶어하는 P, 움직여서 P와 유사하게 만들어주고 싶은 Q

  - 두 확률분포 사이의 거리를 계산할 때 주로 사용
      KL(P || Q) =  ∑ P(x)log₂(P(x)/Q(x))


● 교차 엔트로피와 KL 다이버전스의 관계
  
  P와 Q의 교차 엔트로피 H(P,Q) = H(P) + ∑ P(x)log₂(P(x)/Q(x))
                              = P의 엔트로피 + P와 Q 간의 KL 다이버전스
                                                      ↙ 줄이는 것이 목표

  → 즉, 가지고 있는 데이터 분포 P(x)와 추정한 데이터 분포 Q(x)간의 차이 최소화하는데 교차 엔트로피 사용




□ 최적화

● 순수 수학 최적화와 기계 학습 최적화의 차이
  - 순수 수학의 최적화의 예로는 어떤 함수의 최저점을 찾는 것이지만 

  - 기계 학습의 최적화는 (target distribution을 모르기 때문에) 단지 훈련집합이 주어지고,
    훈련집합에 따라 정해지는 목적함수을 최저점으로 만드는 모델의 매개변수를 찾는다.
      * 주로 SGD(확률론적 경사 하강법 stochastic gradient descent)
        + 손실함수 미분하는 과정 필요 → 오류 역전파 backpropagation 알고리즘

  즉 대상이 달라졌다는 차이점이 있다. 

■ 매개변수 공간의 탐색

● 학습 모델의 매개변수 공간
 - 특징 공간의 높은 차원에 비해 훈련집합의 크기가 작아 참인 확률분포를 구하는 일은 불가능함

 - 따라서 기계 학습은 적절한 모델(가설)을 선택과 목적함수를 정의하고, 
   모델의 매개변수 공간을 탐색하여 목적함수가 최저가 되는 최적점을 찾는 전략 사용
   → 특징 공간에서 해야 하는 일을 모델의 매개변수 공간에서 하는 일을 대치한 셈


최적화의 대상은 특징 공간이 아니고, 학습 모델(or 가설)이 가지고 있는 매개변수 공간( 안에서 손실 함수를 최소화 시키는 영역)이다.


● 학습 모델의 매개변수 공간
 - 특징 공간보다 수 배~수만 배 많은 차원을 가짐
  + MNIST 인식하는 심층학습 모델은 784차원 특징 공간, 수십만~수백만 차원의 매개변수 공간

● 기계학습이 해야 할 일을 식으로 정의하면,
                              ^               ^
   Ｊ(Θ) 를 최소로 하는 최적해 Θ 을 찾아라. 즉, Θ = argmin Ｊ(Θ)
                                                     Θ
   
● 최적화 문제 해결
 - 낱낱탐색 exhaustive search 알고리즘
   + 차원이 조금만 높아져도 적용 불가능
     예) 4차원 Iris에서 각 차원을 1000구간으로 나눈다면 총 1000⁴개의 점을 평가해야 함

 - 무작위탐색 random search 알고리즘
   + 아무 전략이 없는 순진한 알고리즘

● 기계학습이 사용하는 전형적인 알고리즘
  목적함수가 작아지는 방향을 주로 미분으로 찾아냄

● 미분에 의한 최적화
  - 미분의 정의 : 1차 도함수 f'(x)는 함수의 기울기(경사), 즉 값이 커지는 방향을 지시함
                    → -f'(x) 방향에 목적함수의 최저점이 존재
  
  ※ 경사 하강 알고리즘의 핵심 원리 = dΘ로 -f'(x)를 사용
  
  작아지는 방향이라는 것은 손실함수의 미분이 - 되는 것을 사용


■ 미분

● 편미분 partial derivative
  - 변수가 복수인 함수의 미분
  - 미분 값이 이루는 벡터를 경사도(변화도) gradient 라 부름

● 기계학습에서 편미분
  - 매개변수 집합 Θ은 복수 매개변수이므로 편미분을 사용

● 독립변수와 종속변수의 구분
 - y = Wx + b
   x는 독립변수, y는 x에 종속됨
   * 기계학습에서 예측 단계를 위한 해석은 무의미함

● 최적화는 예측 단계가 아니라 학습 단계에 필요
  Θ 이 독립변수이고 error = J(Θ) 이라면 error가 종속변수이다.

● 연쇄법칙 chain rule
  - 합성함수 f(x) = g(h(x)) 와 f(x) = f(h(i(x))) 의 미분
    f'(x) = g'(h(i(x)))h'(i(x))i'(x)

● 다층 퍼셉트론은 합성함수
  하나의 층에서 나온 출력들을 가지고 다시 다음 층에 넣기 때문에 합성함수이다.
  따라서 계산할 때 연쇄법칙을 적용해야 한다.

미분을 구할 때는 한꺼번에 전체를 구하기보다는 요소, 요소, 요소를 순서대로 구한다는 것을 유념하자.


● 야코비언 행렬 Jacobian matrix 자코비안
  어떤 행렬이 있을 때 그 행렬의 각 요소들에 미분값
  행렬 형태를 1차 미분한 것이 야코비안이다.
  - 함수 f: R^d → R^m을 미분하여 얻은 행렬

● 헤세 행렬 Hessian matrix
  행렬을 2차 편도 미분한 것.
  - 2차 편도 함수

신경망에서 연산의 기본단위는 행렬이고 미분할 때 야코비언 자주 쓰인다.


■ 경사 하강 알고리즘

● 경사 하강법 gradient descent 은 낮은 곳을 찾아가는 원리
  - g = dΘ = dJ/dΘ (기울기)이고, ρ는 학습률 learning rate (이동 거리 조절)

   Θ = Θ - ρg
  
  - 함수의 기울기 (경사)를 구하여 기울기가 낮은 쪽으로 반복적으로 이동하여 최소값에 도달


● 집단(무리) batch 경사 하강 알고리즘 
  - 샘플의 경사도를 구하고 평균한 후 한꺼번에 갱신
  - 훈련집합 전체를 다 봐야 갱신이 일어나므로 학습 과정이 오래 걸리는 단점

  배치 경사 하강 알고리즘 BGD

● 확률론적 경사 하강 SGD (stochastic gradient descent) 알고리즘
  - 한 샘플 혹은 작은 집단(무리) mini-batch의 경사도를 계산한 후 즉시 갱신
  - 작은 무리 단위 : 한번 반복하는 일을 한 세대 epoch라 부른 (훈련집합 = 세대)


● 경사 하강 알고리즘 비교

 - 집단 경사 하강 알고리즘 : 정확한 방향으로 수렴. 느림
 - 확률론적 경사 하강 알고리즘 : 수렴이 다소 헤맬 수 있음. 빠름.

 - 갱신 단위
    > Gradient descent = full batch (데이터 전체 epoch 하나)
    > Stochastic Gradient descent = mini-batch (데이터 전체가 아님)

● 추가 경사 하강 알고리즘 

 일반적인 SGD보다는 추가적인 제어 알고리즘을 같이 쓴다.







________________________________________________________________________________________________________________

□ Deep learning Hardware

유명 두 회사
NVIDIA
Intel

■ CPU 
 - GPU에 비해 적은 코어 수
 - 각각의 코어가 더 빠르고 더 우월한 연산력을 가지고 있다.
 - 연속적인 태스크에 우월
■ GPU
 - CPU에 비해 많은 코어 수
 - 각각의 코어가 좀 더 느리고 멍청하다.
 - 병렬적인 태스크에 우월

 행렬 곱은 병렬적으로 이루어지기 때문에 GPU가 CPU보다 훨씬 유리하다.


■ TPU
 - 구글에서 사용하는 용어로 딥러닝 연산에 조금 더 특화되어 있는 하드웨어이다.

TPU가 GPU보다 훨씬 효율적인 모습을 볼 수 있다.


●  programming GPU
- CUDA (NVIDIA only)
- OpenCL 
       어디든 가능 
- HIP  
- Udacity CS 344

● CPU / GPU Communication

 data는 하드디스크에, Model은 GPU에 있다.
 모델을 통해서 연산을 해야하기 때문에.

 연산을 할 때는 하드디스크에 있는 데이터를 빠르게 GPU로 옮겨서 해야하는데,
 빠르게 옮기지 못할 때는 bottleneck 현상이 일어날 수 있다. GPU가 놀게 됨.
 If you aren't careful, training can bottleneck on reading data and transferring to GPU!

 Solutions : 
       - Read all data into RAM (램에 데이터를 옮겨놓는다)
       - Use SSD instead of HDD (HDD 대신에 SSD 써서 빠르게)
       - Use multiple CPU threads to prefetch data (CPU 쓰레드를 조금 더 많이 사용해서 빨리 옮겨서 놀지않게 함)



□ Deep learning Software


Caffe

Torch

Theano


● The point of deep learning frameworks
딥러닝 프레임워크의 장점 3가지 

(1) Quick to develop and test new ideas
(2) Automatically compute gradient
(3) Run it all efficiently on GPU (wrap cuDNN, cuBLAS, etc)



● Pytorch
 - Tensor 를 통해서 연산을 한다. tensor는 numpy의 array와 비슷하지만 GPU 상에서 연산이 가능하다.
 - Autograd : 패키지로, tensor를 통해서 연산을 쌓고 연산그래프를 통해서 자동으로 gradient를 계산해준다. (requires_grad = True)
 - Module : 뉴럴 네트워크 레이어다. 연산의 중간결과를 저장하거나 학습을 해야 할 가중치들을 갖고 있다.